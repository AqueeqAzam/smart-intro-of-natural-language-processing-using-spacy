{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOm7Jk56WRvuuUwID29qjh5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AqueeqAzam/smart-intro-of-natural-language-processing-using-spacy/blob/main/nlp_with_spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP: NLP involves the intersection of linguistics, machine learning. Its primary objective is to bridge the gap between human language and machine understanding."
      ],
      "metadata": {
        "id": "DaiSlb-80TA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spacy intro"
      ],
      "metadata": {
        "id": "3anfN0OD0CzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp('I love nlp')\n",
        "print(doc.text)\n",
        "# print(doc.ents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DXORJmLzd6g",
        "outputId": "c5637f40-eff8-4a11-fd5a-bc06531edede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love nlp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Reading doc`"
      ],
      "metadata": {
        "id": "34hl-dhbbp51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "doc = nlp('Spacy is easy to use then nltk')\n",
        "doc\n",
        "\n",
        "# reading single word\n",
        "doc[0]\n",
        "\n",
        "# reading file\n",
        "file = open('doc.txt').read()\n",
        "doc = nlp(file)\n",
        "doc\n",
        "\n",
        "# customised in one line\n",
        "file1 = nlp(open('doc.txt').read())\n",
        "file1"
      ],
      "metadata": {
        "id": "bqFbSAD6buJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Sentence Token`\n",
        "\n",
        "Tokenization == Splitting or segmenting the text into sentences or tokens"
      ],
      "metadata": {
        "id": "r2299gtte1OS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('doc.txt').read()\n",
        "doc = nlp(file)\n",
        "\n",
        "for sent in doc.sents:\n",
        "    print(sent)\n",
        "\n",
        "# more customisable\n",
        "for num, sent in enumerate(doc.sents):\n",
        "    print('{0}: {1}'.format(num, sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka8F0UTld6jB",
        "outputId": "f485c28e-44db-4301-f4c3-3c4c2f83f550"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK (Natural Language Toolkit)\n",
            "\n",
            "Strengths:\n",
            "\n",
            "Maturity and Flexibility: NLTK is a mature library with a wide range of functionalities for various NLP tasks.\n",
            "It offers a modular approach, allowing you to choose specific tools for your needs.\n",
            "\n",
            "Extensive Documentation and Community:\n",
            "NLTK has a wealth of documentation, tutorials, and a large active community for support.\n",
            "\n",
            "Research Focus: NLTK is well-suited for research and experimentation due to its flexibility and customizability.\n",
            "\n",
            "Weaknesses:\n",
            "\n",
            "Steeper Learning Curve: NLTK can have a steeper learning curve compared to spaCy due to its extensive functionalities and modular nature.\n",
            "You might need to write more code to accomplish specific tasks.\n",
            "\n",
            "Performance: NLTK can be slower than spaCy, especially when dealing with large datasets.\n",
            "\n",
            "spaCy\n",
            "\n",
            "Strengths:\n",
            "\n",
            "\n",
            "Ease of Use: spaCy offers a user-friendly API and comes with pre-trained statistical models for common NLP tasks.\n",
            "This makes it easier to get started and perform tasks quickly.\n",
            "\n",
            "Speed and Efficiency: spaCy is known for its speed and efficiency, particularly for large-scale NLP tasks.\n",
            "\n",
            "Production-Oriented: spaCy is well-suited for production environments due to its focus on performance and ease of use.\n",
            "\n",
            "Weaknesses:\n",
            "\n",
            "Limited Customization: While spaCy offers pre-trained models, it might not provide the same level of customization as NLTK for specific research needs.\n",
            "\n",
            "Less Flexibility: spaCy might not be as flexible as NLTK for tasks requiring extensive control over the NLP pipeline.\n",
            "\n",
            "Choosing Between spaCy and NLTK:\n",
            "\n",
            "The best choice depends on your specific needs and priorities:\n",
            "\n",
            "For Beginners or Production Environments: If you're new to NLP or need a fast and user-friendly library for production use, spaCy is a great option.\n",
            "\n",
            "For Research or Customization: If you need more flexibility and control for research purposes or require extensive customization of the NLP pipeline, NLTK might be a better fit.\n",
            "\n",
            "Here's an analogy:\n",
            "\n",
            "Think of NLTK as a Swiss Army Knife:\n",
            "It has many tools for various tasks, but it might take some time to learn how to use each one effectively.\n",
            "Think of spaCy as a Specialized Power Tool: It excels at specific tasks and is easy to use, but it might not be suitable for every job.\n",
            "\n",
            "Ultimately, you can even experiment with both libraries to see which one suits your workflow and project requirements better.\n",
            "0: NLTK (Natural Language Toolkit)\n",
            "\n",
            "Strengths:\n",
            "\n",
            "Maturity and Flexibility: NLTK is a mature library with a wide range of functionalities for various NLP tasks.\n",
            "1: It offers a modular approach, allowing you to choose specific tools for your needs.\n",
            "\n",
            "2: Extensive Documentation and Community:\n",
            "3: NLTK has a wealth of documentation, tutorials, and a large active community for support.\n",
            "\n",
            "4: Research Focus: NLTK is well-suited for research and experimentation due to its flexibility and customizability.\n",
            "\n",
            "5: Weaknesses:\n",
            "\n",
            "Steeper Learning Curve: NLTK can have a steeper learning curve compared to spaCy due to its extensive functionalities and modular nature.\n",
            "6: You might need to write more code to accomplish specific tasks.\n",
            "\n",
            "7: Performance: NLTK can be slower than spaCy, especially when dealing with large datasets.\n",
            "\n",
            "8: spaCy\n",
            "\n",
            "Strengths:\n",
            "\n",
            "\n",
            "9: Ease of Use: spaCy offers a user-friendly API and comes with pre-trained statistical models for common NLP tasks.\n",
            "10: This makes it easier to get started and perform tasks quickly.\n",
            "\n",
            "11: Speed and Efficiency: spaCy is known for its speed and efficiency, particularly for large-scale NLP tasks.\n",
            "\n",
            "12: Production-Oriented: spaCy is well-suited for production environments due to its focus on performance and ease of use.\n",
            "\n",
            "13: Weaknesses:\n",
            "\n",
            "Limited Customization: While spaCy offers pre-trained models, it might not provide the same level of customization as NLTK for specific research needs.\n",
            "\n",
            "14: Less Flexibility: spaCy might not be as flexible as NLTK for tasks requiring extensive control over the NLP pipeline.\n",
            "\n",
            "15: Choosing Between spaCy and NLTK:\n",
            "\n",
            "The best choice depends on your specific needs and priorities:\n",
            "\n",
            "For Beginners or Production Environments: If you're new to NLP or need a fast and user-friendly library for production use, spaCy is a great option.\n",
            "\n",
            "16: For Research or Customization: If you need more flexibility and control for research purposes or require extensive customization of the NLP pipeline, NLTK might be a better fit.\n",
            "\n",
            "17: Here's an analogy:\n",
            "\n",
            "Think of NLTK as a Swiss Army Knife:\n",
            "18: It has many tools for various tasks, but it might take some time to learn how to use each one effectively.\n",
            "Think of spaCy as a Specialized Power Tool: It excels at specific tasks and is easy to use, but it might not be suitable for every job.\n",
            "\n",
            "19: Ultimately, you can even experiment with both libraries to see which one suits your workflow and project requirements better.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Word Token`"
      ],
      "metadata": {
        "id": "1e8Kxe6EgdPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp('spaCy offers a user-friendly API and comes with pre-trained statistical models for common NLP tasks.')\n",
        "\n",
        "for token in doc:\n",
        "    print(token)\n",
        "\n",
        "split = doc.text.split(' ')\n",
        "print(split)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0s7CzM3ggib",
        "outputId": "433ec9c3-5825-4f23-e860-ec632d94d9a3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy\n",
            "offers\n",
            "a\n",
            "user\n",
            "-\n",
            "friendly\n",
            "API\n",
            "and\n",
            "comes\n",
            "with\n",
            "pre\n",
            "-\n",
            "trained\n",
            "statistical\n",
            "models\n",
            "for\n",
            "common\n",
            "NLP\n",
            "tasks\n",
            ".\n",
            "['spaCy', 'offers', 'a', 'user-friendly', 'API', 'and', 'comes', 'with', 'pre-trained', 'statistical', 'models', 'for', 'common', 'NLP', 'tasks.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Hash values`"
      ],
      "metadata": {
        "id": "iy_lMJZRsQ_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word shape as hash value\n",
        "\n",
        "for word in doc:\n",
        "  print(word.text, word.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "incJZ1MGiNVJ",
        "outputId": "81516429-5783-420a-a02f-1ca5c6cd3c4d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy 12543853910902138754\n",
            "offers 13110060611322374290\n",
            "a 11123243248953317070\n",
            "user 13110060611322374290\n",
            "- 9153284864653046197\n",
            "friendly 13110060611322374290\n",
            "API 3552942401566437853\n",
            "and 4088098365541558500\n",
            "comes 13110060611322374290\n",
            "with 13110060611322374290\n",
            "pre 4088098365541558500\n",
            "- 9153284864653046197\n",
            "trained 13110060611322374290\n",
            "statistical 13110060611322374290\n",
            "models 13110060611322374290\n",
            "for 4088098365541558500\n",
            "common 13110060611322374290\n",
            "NLP 3552942401566437853\n",
            "tasks 13110060611322374290\n",
            ". 12646065887601541794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Part of speech`"
      ],
      "metadata": {
        "id": "NKv1kOeoo-tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in doc:\n",
        "  print('Token =>', word.text, 'Part_of_speech =>', word.pos_, 'dependency_label =>', word.dep_, 'Shape =>', word.shape_, 'alpha_char =>', word.is_alpha, 'word_stop =>', word.is_stop, 'word_tag=>', word.tag_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at5EeWLBisg2",
        "outputId": "fba1f94d-aaf8-4827-f697-f6bc917e4cfe"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token => spaCy Part_of_speech => NOUN dependency_label => nsubj Shape => xxxXx alpha_char => True word_stop => False word_tag=> NN\n",
            "Token => offers Part_of_speech => VERB dependency_label => ROOT Shape => xxxx alpha_char => True word_stop => False word_tag=> VBZ\n",
            "Token => a Part_of_speech => DET dependency_label => det Shape => x alpha_char => True word_stop => True word_tag=> DT\n",
            "Token => user Part_of_speech => NOUN dependency_label => npadvmod Shape => xxxx alpha_char => True word_stop => False word_tag=> NN\n",
            "Token => - Part_of_speech => PUNCT dependency_label => punct Shape => - alpha_char => False word_stop => False word_tag=> HYPH\n",
            "Token => friendly Part_of_speech => ADJ dependency_label => amod Shape => xxxx alpha_char => True word_stop => False word_tag=> JJ\n",
            "Token => API Part_of_speech => NOUN dependency_label => dobj Shape => XXX alpha_char => True word_stop => False word_tag=> NN\n",
            "Token => and Part_of_speech => CCONJ dependency_label => cc Shape => xxx alpha_char => True word_stop => True word_tag=> CC\n",
            "Token => comes Part_of_speech => VERB dependency_label => conj Shape => xxxx alpha_char => True word_stop => False word_tag=> VBZ\n",
            "Token => with Part_of_speech => ADP dependency_label => prep Shape => xxxx alpha_char => True word_stop => True word_tag=> IN\n",
            "Token => pre Part_of_speech => ADJ dependency_label => amod Shape => xxx alpha_char => True word_stop => False word_tag=> JJ\n",
            "Token => - Part_of_speech => ADJ dependency_label => amod Shape => - alpha_char => False word_stop => False word_tag=> JJ\n",
            "Token => trained Part_of_speech => VERB dependency_label => amod Shape => xxxx alpha_char => True word_stop => False word_tag=> VBN\n",
            "Token => statistical Part_of_speech => ADJ dependency_label => amod Shape => xxxx alpha_char => True word_stop => False word_tag=> JJ\n",
            "Token => models Part_of_speech => NOUN dependency_label => pobj Shape => xxxx alpha_char => True word_stop => False word_tag=> NNS\n",
            "Token => for Part_of_speech => ADP dependency_label => prep Shape => xxx alpha_char => True word_stop => True word_tag=> IN\n",
            "Token => common Part_of_speech => ADJ dependency_label => amod Shape => xxxx alpha_char => True word_stop => False word_tag=> JJ\n",
            "Token => NLP Part_of_speech => PROPN dependency_label => compound Shape => XXX alpha_char => True word_stop => False word_tag=> NNP\n",
            "Token => tasks Part_of_speech => NOUN dependency_label => pobj Shape => xxxx alpha_char => True word_stop => False word_tag=> NNS\n",
            "Token => . Part_of_speech => PUNCT dependency_label => punct Shape => . alpha_char => False word_stop => False word_tag=> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Named Entites`\n",
        "\n",
        "A named entity is a “real-world object” that’s assigned a name – for example, a person, a country, a product or a book title"
      ],
      "metadata": {
        "id": "nCGgteDVqW25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I4VVSKQqKRy",
        "outputId": "459bed32-1abc-4f98-a4ec-321963627d22"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple 0 5 ORG\n",
            "U.K. 27 31 GPE\n",
            "$1 billion 44 54 MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Similarity`"
      ],
      "metadata": {
        "id": "ATUKHYZyq_rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
        "doc2 = nlp(\"Fast food tastes very good.\")\n",
        "\n",
        "# Similarity of two documents\n",
        "print(doc1, \"=>\", doc2, doc1.similarity(doc2))\n",
        "\n",
        "# Similarity of tokens and spans\n",
        "french_fries = doc1[2:4]\n",
        "burgers = doc1[5]\n",
        "print(french_fries, \"=>\", burgers, french_fries.similarity(burgers))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz3u_H4wrDHe",
        "outputId": "209e04c1-5a92-4a13-adbd-1751fe11d8f1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like salty fries and hamburgers. => Fast food tastes very good. 0.36760004863009244\n",
            "salty fries => hamburgers 0.43338850140571594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-d51058306d33>:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  print(doc1, \"=>\", doc2, doc1.similarity(doc2))\n",
            "<ipython-input-54-d51058306d33>:10: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Span.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  print(french_fries, \"=>\", burgers, french_fries.similarity(burgers))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"I love coffee\")\n",
        "print(doc.vocab.strings[\"coffee\"])  # 3197928453018144401\n",
        "print(doc.vocab.strings[3197928453018144401])  # 'coffee'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB42lsBnr2WX",
        "outputId": "c85e3cf8-1c76-4d83-f668-6764d7c27673"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3197928453018144401\n",
            "coffee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Lemmatization  `"
      ],
      "metadata": {
        "id": "-HYUOL3SmsIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in doc:\n",
        "  print(\"Token=>\",word.text,\"Lemma=>\",word.lemma_,word.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dyrdigUmvLr",
        "outputId": "2500e4ce-0210-4418-dc5e-19f6f11f1953"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token=> spaCy Lemma=> spacy NOUN\n",
            "Token=> offers Lemma=> offer VERB\n",
            "Token=> a Lemma=> a DET\n",
            "Token=> user Lemma=> user NOUN\n",
            "Token=> - Lemma=> - PUNCT\n",
            "Token=> friendly Lemma=> friendly ADJ\n",
            "Token=> API Lemma=> api NOUN\n",
            "Token=> and Lemma=> and CCONJ\n",
            "Token=> comes Lemma=> come VERB\n",
            "Token=> with Lemma=> with ADP\n",
            "Token=> pre Lemma=> pre ADJ\n",
            "Token=> - Lemma=> - ADJ\n",
            "Token=> trained Lemma=> train VERB\n",
            "Token=> statistical Lemma=> statistical ADJ\n",
            "Token=> models Lemma=> model NOUN\n",
            "Token=> for Lemma=> for ADP\n",
            "Token=> common Lemma=> common ADJ\n",
            "Token=> NLP Lemma=> NLP PROPN\n",
            "Token=> tasks Lemma=> task NOUN\n",
            "Token=> . Lemma=> . PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Stop word removle`"
      ],
      "metadata": {
        "id": "jfZD57J9s5FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Filter tokens that are not stop words and join them back into a sentence\n",
        "filtered_sentence = \" \".join([token.text for token in doc if not token.is_stop])\n",
        "\n",
        "print(filtered_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vUTbSpusvOM",
        "outputId": "ae8ec930-03be-46ac-d27c-5bd64c2cf67c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quick brown fox jumps lazy dog .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Stemming`"
      ],
      "metadata": {
        "id": "LoGSE-sKtYx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Create a stemmer object\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "text = \"Running is fun, but walking is even better for health.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Apply stemming to each token's text using NLTK stemmer\n",
        "stemmed_text = \" \".join([stemmer.stem(token.text) for token in doc])\n",
        "\n",
        "print(stemmed_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVOuVuxHtSfw",
        "outputId": "980a215e-bfcc-4911-b8d6-603817800158"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run is fun , but walk is even better for health .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `n-grams`"
      ],
      "metadata": {
        "id": "qKuDLb7utw9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Define the n-gram value (e.g., bigrams for pairs of words)\n",
        "n = 2\n",
        "\n",
        "# Create a list to store n-grams\n",
        "ngrams = []\n",
        "for i in range(len(doc) - n + 1):\n",
        "  ngrams.append(\" \".join([token.text for token in doc[i:i+n]]))\n",
        "\n",
        "print(ngrams)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDNZ8L8_ttSO",
        "outputId": "122dcd54-ec26-4a59-a187-59aae6db12f0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The quick', 'quick brown', 'brown fox', 'fox jumps', 'jumps over', 'over the', 'the lazy', 'lazy dog', 'dog .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Count Vectorised`"
      ],
      "metadata": {
        "id": "eR3SNWMHurPV"
      }
    },
    {
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# You can specify parameters for the CountVectorizer here (e.g., stop words handling)\n",
        "preprocessed_text = \"You can specify parameters for the CountVectorizer here (e.g., stop words handling\"\n",
        "\n",
        "# Put the preprocessed text in a list so CountVectorizer can iterate over it\n",
        "X = vectorizer.fit_transform([preprocessed_text]) # Changed this line\n",
        "\n",
        "# Access the vocabulary and the count matrix\n",
        "vocabulary = vectorizer.get_feature_names_out()\n",
        "counts = X.toarray()\n",
        "\n",
        "print(vocabulary)\n",
        "print(counts)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0hcrE5CuiHL",
        "outputId": "a9bffbbc-25b7-4531-a05e-da093e790081"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['can' 'countvectorizer' 'for' 'handling' 'here' 'parameters' 'specify'\n",
            " 'stop' 'the' 'words' 'you']\n",
            "[[1 1 1 1 1 1 1 1 1 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `DataFrame`"
      ],
      "metadata": {
        "id": "l7IPB6tTnOVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'wolf': [0], 'dog': [1], 'cat': [2], 'fish': [3], 'bird': [4]})\n",
        "\n",
        "df.head(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "cenBrR7DnTl4",
        "outputId": "88a2312f-a6bd-43f7-f5fe-7b5087abfdb5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   wolf  dog  cat  fish  bird\n",
              "0     0    1    2     3     4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6ce22f9-d072-4575-adf4-9b69fcb94179\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wolf</th>\n",
              "      <th>dog</th>\n",
              "      <th>cat</th>\n",
              "      <th>fish</th>\n",
              "      <th>bird</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6ce22f9-d072-4575-adf4-9b69fcb94179')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6ce22f9-d072-4575-adf4-9b69fcb94179 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6ce22f9-d072-4575-adf4-9b69fcb94179');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"wolf\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dog\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fish\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bird\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4,\n        \"max\": 4,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification Project"
      ],
      "metadata": {
        "id": "53IjDa58v2Jx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`import library`"
      ],
      "metadata": {
        "id": "i7QQeCs_wKBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "bBRvRCIkv8sg"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "` Load spaCy Model and Define Preprocessing Function`"
      ],
      "metadata": {
        "id": "VnlhxNb9wNTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def preprocess_text(text):\n",
        "  doc = nlp(text)\n",
        "  tokens = [token.text.lower() for token in doc]  # Lowercase tokens\n",
        "  return tokens\n"
      ],
      "metadata": {
        "id": "imZpCiIwwRQ6"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Prepare Training Data`"
      ],
      "metadata": {
        "id": "0C2UuivFwaoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data (replace with your actual data)\n",
        "texts = [\"This movie was awesome!\", \"The food was terrible.\", \"I really enjoyed the book.\"]\n",
        "labels = [1, 0, 1]  # 1: Positive, 0: Negative\n",
        "\n",
        "# Preprocess text data\n",
        "preprocessed_texts = [\" \".join(preprocess_text(text)) for text in texts]\n",
        "\n",
        "# Train-test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(preprocessed_texts, labels, test_size=0.2)\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "x_train_features = vectorizer.fit_transform(x_train)\n",
        "x_test_features = vectorizer.transform(x_test)\n"
      ],
      "metadata": {
        "id": "0Rkd34nBwcV3"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Feature Engineering with CountVectorizer`"
      ],
      "metadata": {
        "id": "pah8arvpwo8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "x_train_features = vectorizer.fit_transform(x_train)\n",
        "x_test_features = vectorizer.transform(x_test)"
      ],
      "metadata": {
        "id": "nb28OH6SwrwL"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Train a Logistic Regression Model`"
      ],
      "metadata": {
        "id": "V6qoimyHxsZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression()\n",
        "classifier.fit(x_train_features, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "JE3kH9vlxvID",
        "outputId": "1f56aa24-6333-4bc7-8162-f1f28f7f97cd"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "` Evaluate and Predict:`\n"
      ],
      "metadata": {
        "id": "octzy3usx1-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "  # Make sure to return a string, not a list\n",
        "  return text.lower()\n",
        "\n",
        "# Predict on new text data\n",
        "new_text = \"This is a great restaurant!\"\n",
        "new_text_features = vectorizer.transform([preprocess_text(new_text)])\n",
        "prediction = classifier.predict(new_text_features)[0]\n",
        "\n",
        "if prediction == 0:\n",
        "  print(\"Negative sentiment\")\n",
        "else:\n",
        "  print(\"Positive sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqAIrWsYx7vT",
        "outputId": "73dc7d72-3253-43bd-f495-6e55e2d8957b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Have a nice day"
      ],
      "metadata": {
        "id": "kYzpPk3RzRBo"
      }
    }
  ]
}